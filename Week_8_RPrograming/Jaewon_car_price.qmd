---
title: "Jaewon_car_price"
author: "Lim Jaewon"
format: html
editor: visual
---
### 목적 : 유의한 독립변수들을 찾아  <span style='background-color: #fff5b1'>다중회귀분석</span>을 사용하여 자동차의 값을 예측해본다.  
### 목차 
- 1. Dataset, library 로딩
- 2. 데이터 전처리
- 3. 데이터 통계분석
- 4. 회귀모형을 사용한 예측
- 5. 아쉬웠던 점

# 1. Dataset, library 로딩

```{r}
library(VIM)
library(leaps)
library(psych)
library(car)
library(ggplot2)
library(patchwork)
library(tidyverse)

carDF <- read.csv('car_price.csv', fileEncoding = 'cp949', encoding = 'cp949')
head(carDF)
```

# 2. 데이터 전처리

## 2-1 자료형 확인 및 변경
- chr -> factor 자료형으로 변경

```{r}
carDF[sapply(carDF, is.character)] <- lapply(carDF[sapply(carDF, is.character)], as.factor)
carDF$year <- as.factor(carDF$year)
carDF$LPG <- as.factor(carDF$LPG)
carDF$hybrid <- as.factor(carDF$hybrid)
str(carDF)
```

## 2-2 결측치 확인 및 처리방안 구상
- 3군데의 열에서 결측치가 관측되었고 결측치의 수가 얼마되지 않기에 <span style='background-color: #fff5b1'>제거</span>해주었음.
- 409개 행 -> 407개 행

```{r}
dim(carDF)
VIM::aggr(carDF)
carDF <- na.omit(carDF)
dim(carDF)
VIM::aggr(carDF)
```

## 2-3 종속변수(selling_price) 확인
- <span style='background-color: #fff5b1'>Target변수인 sell_price</span>가 왼쪽으로 너무 치우쳐져 있음.
- 회귀분석에 있어서 종속변수의 경우 정규분포를 따르는 것이 좋기때문에 log화 해주었음.
- 샤피로 테스트 결과 확인.
```{r}
hist(carDF$sell_price)
qqnorm(carDF$sell_price)
hist(log(carDF$sell_price))
qqnorm(log(carDF$sell_price))
shapiro.test(log(carDF$sell_price))
```

## 2-4 데이터셋에 대한 EDA분석
- sell_price에서 이상치라고는 할 수 없지만 회귀모형 예측률을 높여주기 위해 9이상의 값들 제거.

```{r}
par(mfrow=c(2,3))
boxplot(log(carDF$sell_price), main = 'sell_price')
boxplot(carDF$mielage, main = 'mielage')
boxplot(carDF$hp, main = 'hp')
boxplot(carDF$torque, main = 'torque')
boxplot(carDF$displacement, main = 'displacement')
boxplot(carDF$wt, main = 'wt')
par(mfrow=c(1,1))

carDF <- carDF[log(carDF$sell_price) < 9, ]
```

### 2-4-1 이상치 제거후 sell_prcie확인
- 이상치를 제거한 후 정규분포를 잘 따르는 것으로 확인되었다.
```{r}
hist(log(carDF$sell_price))
qqnorm(log(carDF$sell_price))
```

### 2-4-2 범주형 데이터 확인
- LPG, hybrid열의 경우 한쪽으로 매우 많이 값이 치우쳐 져있기 때문에, <span style='background-color: #fff5b1'>유의한 변수가 아니라고 판단</span>하여 회귀모델 생성에 사용하지 않을것.

```{r}
g1 <- ggplot(data = carDF, aes(brand)) + geom_bar(aes(fill=brand)) + theme_bw()
g2 <- ggplot(data = carDF, aes(year)) + geom_bar(aes(fill=year)) + theme_bw()
g3 <- ggplot(data = carDF, aes(type)) + geom_bar(aes(fill=type)) + theme_bw()
g4 <- ggplot(data = carDF, aes(fuel_type)) + geom_bar(aes(fill=fuel_type)) + theme_bw()
g5 <- ggplot(data = carDF, aes(LPG)) + geom_bar(aes(fill=LPG)) + theme_bw()
g6 <- ggplot(data = carDF, aes(hybrid)) + geom_bar(aes(fill=hybrid)) + theme_bw()
g7 <- ggplot(data = carDF, aes(transmission_type)) + geom_bar(aes(fill=transmission_type)) + theme_bw()
(g1 + g2) / (g3 + g4) / (g5 + g6 + g7)

```

# 3. 데이터 통계분석

## 3-1 종속변수(sell_price)에 대한 전체변수 회귀모형 fitting

```{r}
model <- lm(sell_price~., data = carDF)
summary(model)
```

## 3-2 변수선택('forward', 'backward', 'stepwise')
- <span style='background-color: #fff5b1'>유의하지 않은 변수가 많이 관측</span>된다.
- 따라서 3가지의 변수선택법을 사용하여 변수를 필터링 해본다.

### 3-2-1 전진선택법
- 최종 선택된 유의한 변수 : brand, type, displacement, wt, transmission_type, mielage, torque / 7개
- Adjusted R-squared: 0.8368

```{r}
model_forward <- lm(sell_price ~ 1, data = carDF)
model_forward <- step(model_forward, scope=list(lower=model_forward, upper=model), direction = "forward")
summary(model_forward)
```

### 3-2-2 후진선택법
- 최종 선택된 유의한 변수 : brand, type, displacement, wt, transmission_type, mielage, torque / 7개
- Adjusted R-squared: 0.8368

```{r}
model_backward <- lm(sell_price ~ 1, data = carDF)
model_backward <- step(model, scope=list(lower=model_backward, upper=model), direction = "backward")
summary(model_backward)
```

### 3-2-3 단계선택법
- 최종 선택된 유의한 변수 : brand, type, displacement, wt, transmission_type, mielage, torque / 7개
- Adjusted R-squared: 0.8368

```{r}
model_both <- lm(sell_price ~ 1, data = carDF)
model_both <- step(model_both, scope=list(lower=model_both, upper=model), direction = "both")
summary(model_both)
```

### 3-2-4 결론
- 3가지의 변수선택법 모두 7개의 변수가 유의하다고 나오므로 7개의 변수를 독립변수로써 사용.
- 하지만 7개라는 많은 변수는 자칫 모형이 복잡해질수도 있고, 과적합의 문제가 발생할 수도 있다.

## 3-3 다중공선성 진단.
- 일반적으로 회귀분석에서는 독립변수(설명변수)들이 모두 독립이라고 가정한다. 그래야 알아보고자 하는 변수의 영향력만을 오롯이 알 수 있기 때문이다.
- 만약 두 독립변수가 서로에게 영향을 주고 있다면? 회귀모델의 설명력이 낮아진다.

### 3-3-1 산점도 그래프 
- 잘 보이진 않지만 wt ~ torque, displacement ~ torque 등 상관관계가 높아보이는 변수들이 보인다.

```{r}
pairs(~ brand + type + displacement + wt + transmission_type + mielage + torque, data = carDF, pch = 21, bg = c("red", "blue", "green"))

```

### 3-3-2 vif(분산팽창요인)을 사용하여 다중공선성 계산
- 가장 높은 값을 가지는 <span style='background-color: #fff5b1'>wt(중량)을 제거</span>한 후 회귀모형을 다시 만들어 주었다.
```{r}
model <- lm(sell_price ~ brand + type + displacement + wt + transmission_type + mielage + torque, data = carDF)
vif(model)
model <- lm(sell_price ~ brand + type + displacement + transmission_type + mielage + torque, data = carDF)
```

## 3-3 회귀모형 진단
- 선형성, 정규성은 만족, 등분산성에서 아쉬운 모습을 보여주지만, 그래도 괜찮은 회귀모형이 만들어졌다.

```{r}
plot(model)
```

# 4. 회귀모형을 사용한 예측

## 4-1 상한과 하한을 설정하여 구간안에 들어오면 예측성공한 것으로 판단.(전체 데이터 사용)
- pre라는 데이터프레임 생성, fit값과 상한, 하한값을 저장, 실제 자동차의 sell_price가 예측범위 안에 들어온다면 TRUE로 판단.

```{r}
model <- lm(sell_price ~ brand + type + displacement + transmission_type + mielage + torque, data = carDF)
pre <- predict(model, test_modedl = carDF, interval = "prediction")
pre <- as.data.frame(pre)
pre <- cbind(pre, carDF$sell_price)
Success <- NA
pre <- cbind(pre, Success)
pre$Success[pre$'carDF$sell_price' >= pre$lwr & pre$'carDF$sell_price' <= pre$upr] <- T
pre$Success[is.na(pre$Success)] <- F
head(pre)
```

### 4-1-1 성공한 비율을 계산하여 회귀모형의 예측률을 계산
- RMSE값(평균 제곱근 오차, 잔차 측정의 척도): <span style='background-color: #fff5b1'>507.9306</span>
- 예측 성공률: 약 <span style='background-color: #fff5b1'>93%</span>

```{r}
sqrt(sum(sapply(carDF[, 1] - predict(model, carDF[, -1]), FUN = function(x) {x^2})) / dim(carDF)[1])
sum(pre$Success=="TRUE")/dim(pre)[1]
```

## 4-2 상한과 하한을 설정하여 구간안에 들어오면 예측성공한 것으로 판단.(train - test 데이터 분할)

```{r}
set.seed(1)
test_index<- sample(1:dim(carDF)[1], as.integer(dim(carDF)[1]*0.2) , replace = F)
train_df <- carDF[-test_index,]
test_df <- carDF[test_index,]

model <- lm(sell_price ~ brand + type + displacement + transmission_type + mielage + torque, data = train_df)

pre <- predict(model, test_df[, -1], interval = "prediction")
pre <- as.data.frame(pre)
pre <- cbind(pre, test_df$sell_price)
Success <- NA
pre <- cbind(pre, Success)
pre$Success[pre$'test_df$sell_price' >= pre$lwr & pre$'test_df$sell_price' <= pre$upr] <- T
pre$Success[is.na(pre$Success)] <- F
head(pre)
```

### 4-2-1 성공한 비율을 계산하여 회귀모형의 예측률을 계산
- RMSE값(평균 제곱근 오차): <span style='background-color: #fff5b1'>603.4126</span>
- 예측 성공률: 약 <span style='background-color: #fff5b1'>96%</span>

```{r}
sqrt(sum(sapply(test_df[, 1] - predict(model, test_df[, -1]), FUN = function(x) {x^2})) / dim(test_df)[1])
sum(pre$Success=="TRUE")/dim(pre)[1]
```

# 5. 아쉬웠던 점
- 내 임의로 변수들을 제거하지 말고, 여러개의 회귀모형을 만들어서 비교하였다면 더 적합한 모형을 찾을 수 있었을 것 같다.
- 회귀모형을 사용한 예측의 과정에서 예측 성공률을 높게 나왔지만, 이는 예측의 범위가 너무 넓기 때문이라고 생각한다. RMSE값의 경우도 회귀모형끼리의 비교에 적합하기 때문에, 회귀모형 신뢰성 판단에 쓸 수 있는 다른 지표들의 보완이 필요할 것 같다.





